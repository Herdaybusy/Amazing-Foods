{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extracted successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_excel(r'Dataset\\Raw Data\\Amazing food dataset..xlsx')\n",
    "    print('Data Extracted successfully')\n",
    "except Exception as e:\n",
    "    print (f'an error occured: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates values\n",
    "\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Transformation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Date                    1000 non-null   datetime64[ns]\n",
      " 1   ProductName             1000 non-null   object        \n",
      " 2   Quantity                1000 non-null   int64         \n",
      " 3   UnitPrice               1000 non-null   float64       \n",
      " 4   StoreLocation           1000 non-null   object        \n",
      " 5   PaymentType             1000 non-null   object        \n",
      " 6   PromotionApplied        1000 non-null   bool          \n",
      " 7   Weather                 1000 non-null   object        \n",
      " 8   Temperature             900 non-null    float64       \n",
      " 9   StaffPerformanceRating  1000 non-null   object        \n",
      " 10  CustomerFeedback        900 non-null    object        \n",
      " 11  DeliveryTime_min        1000 non-null   int64         \n",
      " 12  OrderType               1000 non-null   object        \n",
      " 13  CustomerName            1000 non-null   object        \n",
      " 14  CustomerAddress         1000 non-null   object        \n",
      " 15  Customer_PhoneNumber    1000 non-null   object        \n",
      " 16  CustomerEmail           900 non-null    object        \n",
      " 17  Staff_Name              1000 non-null   object        \n",
      " 18  Staff_Email             900 non-null    object        \n",
      " 19  DayOfWeek               1000 non-null   object        \n",
      " 20  TotalSales              1000 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(3), int64(2), object(14)\n",
      "memory usage: 165.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing value\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Handle the misiing values\n",
    "\n",
    "data = data.fillna({\n",
    "    'Temperature': data['Temperature'].mean(),\n",
    "    'CustomerFeedback': 'Unknown',\n",
    "    'CustomerEmail': 'Unknown',\n",
    "    'Staff_Email': 'Unknown'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "\n",
    "data = data.rename(columns ={\n",
    "    'ProductName' : 'Product_Name',\n",
    "    'UnitPrice' : 'Unit_Price',\n",
    "    'StoreLocation' : 'Store_Location',\n",
    "    'StaffPerformanceRating' : 'Staff_Performance_Rating',\n",
    "    'CustomerFeedback' : 'Customer_Feedback',\n",
    "    'DeliveryTime_min' : 'Delivery_Time_min',\n",
    "    'OrderType' : 'Order_Type',\n",
    "    'CustomerName' : 'Customer_Name',\n",
    "    'CustomerAddress' : 'Customer_Address',\n",
    "    'CustomerEmail' : 'Customer_Email',\n",
    "    'DayOfWeek' : 'Day_Of_Week',\n",
    "    'TotalSales' : 'Total_Sales',\n",
    "    'PaymentType': 'Payment_Type',\n",
    "    'PromotionApplied' : 'Promotion_Applied'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data to local machine\n",
    "\n",
    "data.to_csv(r'Dataset\\Cleaned Data\\Clean data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the product table\n",
    "\n",
    "products = data[['Product_Name', 'Unit_Price']].drop_duplicates().reset_index(drop=True)\n",
    "products['Product_id'] = np.random.randint(10000, 99999, size=len(products))\n",
    "products = products[['Product_id', 'Product_Name', 'Unit_Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customers table\n",
    "\n",
    "customers = data[['Customer_Name', 'Customer_Address', 'Customer_PhoneNumber', 'Customer_Email', 'Customer_Feedback']].drop_duplicates().reset_index(drop=True)\n",
    "customers ['Customer_id'] = np.random.randint(1000, 9999, size = len(customers))\n",
    "customers = customers[['Customer_id','Customer_Name', 'Customer_Address', 'Customer_PhoneNumber', 'Customer_Email', 'Customer_Feedback']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dates table\n",
    "\n",
    "dates = data[['Date','Day_Of_Week' ]].drop_duplicates().reset_index(drop=True)\n",
    "dates['Date_id'] = np.random.randint(10000,99999, size=len(dates)) \n",
    "dates = dates[['Date_id', 'Date','Day_Of_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create staff table\n",
    "\n",
    "staff = data [['Staff_Name', 'Staff_Email','Staff_Performance_Rating']].drop_duplicates().reset_index(drop=True)\n",
    "staff ['staff_id'] = np.random.randint(10000, 99999, size=len(staff))\n",
    "staff = staff [['staff_id', 'Staff_Name', 'Staff_Email','Staff_Performance_Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact table\n",
    "\n",
    "fact_table = data.merge(customers, on=['Customer_Name', 'Customer_Address', 'Customer_PhoneNumber', 'Customer_Email', 'Customer_Feedback'], how='left')\\\n",
    "                .merge(products, on=['Product_Name', 'Unit_Price'], how='left')\\\n",
    "                    .merge(dates, on=['Date','Day_Of_Week' ], how='left')\\\n",
    "                        .merge(staff, on=['Staff_Name', 'Staff_Email','Staff_Performance_Rating'], how='left')\n",
    "                        \n",
    "fact_table= fact_table[['Customer_id', 'Product_id', 'Date_id', 'staff_id','Quantity','Store_Location',\n",
    "                        'Payment_Type', 'Promotion_Applied', 'Weather', 'Temperature', 'Delivery_Time_min',\n",
    "                        'Order_Type', 'Total_Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tables to local machine\n",
    "products.to_csv(r'Dataset\\Cleaned Data\\Products data.csv', index=False)\n",
    "customers.to_csv(r'Dataset\\Cleaned Data\\Customers data.csv', index=False)\n",
    "staff.to_csv(r'Dataset\\Cleaned Data\\Staff data.csv',index=False)\n",
    "dates.to_csv(r'Dataset\\Cleaned Data\\Dates data.csv', index=False)\n",
    "fact_table.to_csv(r'Dataset\\Cleaned Data\\Fact table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "connect_str = os.getenv('Connect_str')\n",
    "container_name = os.getenv('Container_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data\\clean data.csv loaded into Azure Blob Storage\n",
      "Cleaned Data\\Products data.csv loaded into Azure Blob Storage\n",
      "Cleaned Data\\Customers data.csv loaded into Azure Blob Storage\n",
      "Cleaned Data\\Staff data.csv loaded into Azure Blob Storage\n",
      "Cleaned Data\\Dates data.csv loaded into Azure Blob Storage\n",
      "Cleaned Data\\Fact table.csv loaded into Azure Blob Storage\n"
     ]
    }
   ],
   "source": [
    "# Create a BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Loading data to Azure Blob Storage\n",
    "files = [\n",
    "    (data, r'Cleaned Data\\clean data.csv' ),\n",
    "    (products, r'Cleaned Data\\Products data.csv'),\n",
    "    (customers, r'Cleaned Data\\Customers data.csv'),\n",
    "    (staff, r'Cleaned Data\\Staff data.csv'),\n",
    "    (dates, r'Cleaned Data\\Dates data.csv'),\n",
    "    (fact_table, r'Cleaned Data\\Fact table.csv')\n",
    "]\n",
    "\n",
    "for file, blob_name in files:\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    output = file.to_csv(index=False)\n",
    "    blob_client.upload_blob(output, overwrite=True)\n",
    "    print(f'{blob_name} loaded into Azure Blob Storage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
